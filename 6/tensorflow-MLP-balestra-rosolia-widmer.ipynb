{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with TensorFlow 2.0\n",
    "The objective of the exercise is to implement computational graphs in TensorFlow 2.0 to train and use such an architecture. The constraints we put ourselves is to use **low-level** functions of TensorFlow, i.e. we will not use high-level functions to compose layers and to train the parameters.\n",
    "\n",
    "If you get this error in the execution of the first cell: ` ModuleNotFoundError: No module named 'tensorflow' `, it probably means TensorFlow 2.0 is not installed yet on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data set ready. N=60000, D=784, n_classes=10\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# MNIST Dataset Preparation #\n",
    "#############################\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train_vec),(x_test, y_test_vec) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train_vec, 10, dtype='float64')\n",
    "y_test = tf.keras.utils.to_categorical(y_test_vec, 10, dtype='float64')\n",
    "N = x_train.shape[0]         # number of samples\n",
    "D = x_train.shape[1]         # dimension of input sample\n",
    "n_classes = y_train.shape[1] # output dim\n",
    "print('MNIST data set ready. N={}, D={}, n_classes={}'.format(N,D,n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample a random batch from dataset\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0,len(data))  # create an array of index values\n",
    "    np.random.shuffle(idx)        # shuffle it\n",
    "    idx = idx[:num]               # take the first n indexes = size of batch\n",
    "    data_shuffle = data[idx]      # extract the batch using the random indexes\n",
    "    labels_shuffle = labels[idx]  # extract the labels using the random indexes\n",
    "\n",
    "    return data_shuffle, labels_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, loss = 53.371737669225105\n",
      "epoch = 1, loss = 40.4128861794632\n",
      "epoch = 2, loss = 37.69692418541751\n",
      "epoch = 3, loss = 35.22259789931115\n",
      "epoch = 4, loss = 33.074851051301174\n",
      "epoch = 5, loss = 31.04948827790961\n",
      "epoch = 6, loss = 29.242082010150536\n",
      "epoch = 7, loss = 27.913974977167484\n",
      "epoch = 8, loss = 26.55273814998674\n",
      "epoch = 9, loss = 25.32682075931008\n",
      "epoch = 10, loss = 24.31382764799379\n",
      "epoch = 11, loss = 23.30969060045229\n",
      "epoch = 12, loss = 22.391840104020325\n",
      "epoch = 13, loss = 21.642140554639123\n",
      "epoch = 14, loss = 20.957618640301796\n",
      "epoch = 15, loss = 20.2808369299848\n",
      "epoch = 16, loss = 19.70459929840204\n",
      "epoch = 17, loss = 19.06271291180454\n",
      "epoch = 18, loss = 18.609543913866826\n",
      "epoch = 19, loss = 18.177047055022744\n",
      "epoch = 20, loss = 17.629859673119828\n",
      "epoch = 21, loss = 17.345047897635474\n",
      "epoch = 22, loss = 16.964046843886198\n",
      "epoch = 23, loss = 16.622196658723716\n",
      "epoch = 24, loss = 16.43980024912954\n",
      "epoch = 25, loss = 16.012872525921605\n",
      "epoch = 26, loss = 15.768472802117598\n",
      "epoch = 27, loss = 15.489752261624554\n",
      "epoch = 28, loss = 15.30914780032506\n",
      "epoch = 29, loss = 15.082253207459006\n",
      "epoch = 30, loss = 14.954357583526525\n",
      "epoch = 31, loss = 14.705467694052446\n",
      "epoch = 32, loss = 14.562837223774782\n",
      "epoch = 33, loss = 14.361872062520451\n",
      "epoch = 34, loss = 14.032268791566256\n",
      "epoch = 35, loss = 14.02481244967829\n",
      "epoch = 36, loss = 13.756221568731139\n",
      "epoch = 37, loss = 13.676941872399173\n",
      "epoch = 38, loss = 13.567047407817558\n",
      "epoch = 39, loss = 13.424942475219735\n",
      "epoch = 40, loss = 13.259183407935845\n",
      "epoch = 41, loss = 13.075170162478393\n",
      "epoch = 42, loss = 13.084042071423907\n",
      "epoch = 43, loss = 12.938548114964574\n",
      "epoch = 44, loss = 12.776237759715135\n",
      "epoch = 45, loss = 12.650808838567794\n",
      "epoch = 46, loss = 12.647943717891991\n",
      "epoch = 47, loss = 12.519610015959353\n",
      "epoch = 48, loss = 12.369100340028604\n",
      "epoch = 49, loss = 12.2693183703399\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Training phase #\n",
    "##################\n",
    "\n",
    "E = 50                # number of epochs\n",
    "B = 128               # batch size\n",
    "N = x_train.shape[0]  # number of samples\n",
    "D = x_train.shape[1]  # dimension of input sample\n",
    "H = 300               # number of neurons\n",
    "A = 0.01              # learning rate alpha\n",
    "\n",
    "##############################################\n",
    "#  COMPLETE CODE BELOW WHERE YOU SEE # ...   #\n",
    "##############################################\n",
    "\n",
    "# Build the computational graph\n",
    "@tf.function # this decorator tells tf that a graph is defined\n",
    "def mlp_train(x, y, alpha):\n",
    "    # define nodes for forward computation for hidden neurons h and output neurons y_pred\n",
    "    # h = ...  output of first layer after ReLu activation\n",
    "    #h = tf.nn.relu(tf.matmul(x, w1)+b1)\n",
    "    h = tf.maximum(tf.matmul(x, w1) + b1, 0.0)\n",
    "    # y_pred = ... output of second layer after sigmoid activation\n",
    "    #y_pred = tf.maximum((tf.matmul(h,w2)+b2),0)\n",
    "    y_pred = tf.sigmoid(tf.matmul(h, w2) + b2)\n",
    "    # define nodes for forward computation for hidden neurons h and output neurons y_pred\n",
    "    #print(\"y: \", y)\n",
    "    #print(\"y_pred: \", y_pred)\n",
    "    diff = y_pred - y\n",
    "    loss = tf.reduce_mean(tf.pow(diff,2))\n",
    "    \n",
    "    # define the gradients\n",
    "    grad_w1, grad_b1, grad_w2, grad_b2 = tf.gradients(ys=loss, xs=[w1,b1,w2,b2])\n",
    "    \n",
    "    # compute the new values of the gradients with the assign method (see slides)\n",
    "    w1.assign(w1 - alpha * grad_w1)\n",
    "    b1.assign(b1 - alpha * grad_b1)\n",
    "    w2.assign(w2 - alpha * grad_w2)\n",
    "    b2.assign(b2 - alpha * grad_b2)\n",
    "    return y_pred, loss\n",
    "\n",
    "# Init the tf.Variablesw 1, b1, w2, b2 following the given examples\n",
    "w1 = tf.Variable(tf.random.truncated_normal((D, H), stddev = 0.1, dtype='float64'))\n",
    "b1 = tf.Variable(tf.constant(0.0, shape=[H], dtype='float64'))\n",
    "w2 = tf.Variable(tf.random.truncated_normal((H, n_classes), stddev = 0.1, dtype='float64'))\n",
    "b2 = tf.Variable(tf.constant(0.0, shape=[n_classes], dtype='float64'))\n",
    "\n",
    "# Run the computational graph\n",
    "J = [] # to store the evolution of loss J for each epoch\n",
    "for epoch in range(E):\n",
    "    J_epoch = 0.0\n",
    "    for _ in range(int(N/B)): # number of batches to visit for 1 epoch\n",
    "        # get batches calling the next_batch method provided above\n",
    "        x_train_batch, y_train_batch = next_batch(B,x_train, y_train)\n",
    "        #print(\"y_train_batch: \", y_train_batch)\n",
    "        with tf.device('/CPU:0'):  # change to /GPU:0 to move it to GPU\n",
    "            # call the graph with the batched input, target and alpha A\n",
    "             out = mlp_train(x_train_batch, y_train_batch, A)\n",
    "        y_pred, loss_val = out\n",
    "        J_epoch += loss_val\n",
    "    J.append(J_epoch)\n",
    "    print(\"epoch = {}, loss = {}\".format(epoch, J_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e34d79a518>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the evolution of the loss\n",
    "plt.plot(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass on test set done.\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Testing phase #\n",
    "#################\n",
    "\n",
    "N = x_test.shape[0]  # number of samples\n",
    "D = x_test.shape[1]  # dimension of input sample\n",
    "\n",
    "##############################################\n",
    "#  COMPLETE CODE BELOW WHERE YOU SEE # ...   #\n",
    "##############################################\n",
    "# Build the computational graph\n",
    "@tf.function # this decorator tells tf that a graph is defined\n",
    "def mlp_test(x, y):\n",
    "    #h = tf.nn.relu(tf.matmul(x, w1)+b1)\n",
    "    #y_pred = tf.maximum((tf.matmul(h,w2)+b2),0)\n",
    "    h = tf.maximum(tf.matmul(x, w1) + b1, 0.0)\n",
    "    y_pred = tf.sigmoid(tf.matmul(h, w2) + b2)\n",
    "    return y_pred\n",
    "\n",
    "# Run the computational graph\n",
    "with tf.device('/CPU:0'):  # change to /GPU:0 to move it to GPU\n",
    "    y_pred_test = mlp_test(x_test, y_test)\n",
    "\n",
    "print('Forward pass on test set done.')\n",
    "# At this stage, y_pred_test should contain the matrix of outputs on the test set with shape (N_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples  :  10000\n",
      "# correct  :  8810\n",
      "# missed   :  1190\n",
      "accuracy   :  88.10 %\n",
      "error rate :  11.90 %\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "y_winner = np.argmax(y_pred_test, axis=1)\n",
    "N_test = y_winner.size\n",
    "num_correct = (y_winner == y_test_vec).sum()\n",
    "num_missed = N_test - num_correct\n",
    "accuracy = num_correct * 1.0 / N_test\n",
    "error_rate = num_missed * 1.0 / N_test\n",
    "print('# samples  : ', N_test)\n",
    "print('# correct  : ', num_correct)\n",
    "print('# missed   : ', num_missed)\n",
    "print('accuracy   :  %2.2f %%'% (accuracy*100.0))\n",
    "print('error rate :  %2.2f %%'% (error_rate*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data set ready. N=60000, D=784, n_classes=10\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# MNIST Dataset Preparation #\n",
    "#############################\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train_vec),(x_test, y_test_vec) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train_vec, 10, dtype='float64')\n",
    "y_test = tf.keras.utils.to_categorical(y_test_vec, 10, dtype='float64')\n",
    "N = x_train.shape[0]         # number of samples\n",
    "D = x_train.shape[1]         # dimension of input sample\n",
    "n_classes = y_train.shape[1] # output dim\n",
    "print('MNIST data set ready. N={}, D={}, n_classes={}'.format(N,D,n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(300, input_shape=(D,), use_bias=True, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, input_shape=(D,), use_bias=True, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 238,510\n",
      "Trainable params: 238,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = tf.keras.optimizers.SGD(learning_rate=A)\n",
    "model.compile(optimizers=sgd, loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history1 = model.fit(x_train, y_train, epochs = E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0125 - accuracy: 0.9304 - val_loss: 0.0070 - val_accuracy: 0.9611\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0056 - accuracy: 0.9690 - val_loss: 0.0049 - val_accuracy: 0.9743\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0042 - accuracy: 0.9776 - val_loss: 0.0043 - val_accuracy: 0.9768\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0033 - accuracy: 0.9826 - val_loss: 0.0040 - val_accuracy: 0.9790\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0028 - accuracy: 0.9856 - val_loss: 0.0039 - val_accuracy: 0.9791 0s - loss: 0 - ETA: 0s - loss: 0.0027 - accura\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0024 - accuracy: 0.9873 - val_loss: 0.0036 - val_accuracy: 0.9807\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0021 - accuracy: 0.9889 - val_loss: 0.0038 - val_accuracy: 0.9797\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0018 - accuracy: 0.9902 - val_loss: 0.0036 - val_accuracy: 0.9815\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0016 - accuracy: 0.9912 - val_loss: 0.0035 - val_accuracy: 0.9829\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0015 - accuracy: 0.9922 - val_loss: 0.0035 - val_accuracy: 0.9816\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0013 - accuracy: 0.9930 - val_loss: 0.0037 - val_accuracy: 0.9803\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0012 - accuracy: 0.9934 - val_loss: 0.0037 - val_accuracy: 0.9810\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0011 - accuracy: 0.9938 - val_loss: 0.0036 - val_accuracy: 0.9821\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0010 - accuracy: 0.9940 - val_loss: 0.0035 - val_accuracy: 0.9826\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 9.5505e-04 - accuracy: 0.9947 - val_loss: 0.0035 - val_accuracy: 0.9824\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 8.7660e-04 - accuracy: 0.9946 - val_loss: 0.0034 - val_accuracy: 0.9820\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 8.0073e-04 - accuracy: 0.9951 - val_loss: 0.0036 - val_accuracy: 0.9833\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 7.6427e-04 - accuracy: 0.9954 - val_loss: 0.0034 - val_accuracy: 0.9829\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 7.2280e-04 - accuracy: 0.9955 - val_loss: 0.0036 - val_accuracy: 0.9825\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 6.8492e-04 - accuracy: 0.9957 - val_loss: 0.0034 - val_accuracy: 0.9836\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 6.4496e-04 - accuracy: 0.9958 - val_loss: 0.0036 - val_accuracy: 0.9828\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 6.1216e-04 - accuracy: 0.9959 - val_loss: 0.0036 - val_accuracy: 0.9826\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 5.7716e-04 - accuracy: 0.9961 - val_loss: 0.0037 - val_accuracy: 0.9819\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 5.6652e-04 - accuracy: 0.9962 - val_loss: 0.0035 - val_accuracy: 0.9830\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 5.2179e-04 - accuracy: 0.9963 - val_loss: 0.0035 - val_accuracy: 0.9835\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 5.2648e-04 - accuracy: 0.9964 - val_loss: 0.0035 - val_accuracy: 0.9826\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 4.9308e-04 - accuracy: 0.9965 - val_loss: 0.0035 - val_accuracy: 0.9834\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 4.7196e-04 - accuracy: 0.9966 - val_loss: 0.0036 - val_accuracy: 0.9828\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 4.5758e-04 - accuracy: 0.9966 - val_loss: 0.0037 - val_accuracy: 0.9817\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 4.4585e-04 - accuracy: 0.9970 - val_loss: 0.0035 - val_accuracy: 0.9832\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 4.2302e-04 - accuracy: 0.9969 - val_loss: 0.0036 - val_accuracy: 0.9831\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 4.0747e-04 - accuracy: 0.9969 - val_loss: 0.0037 - val_accuracy: 0.9833\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 4.0161e-04 - accuracy: 0.9970 - val_loss: 0.0036 - val_accuracy: 0.9830\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 3.9418e-04 - accuracy: 0.9971 - val_loss: 0.0037 - val_accuracy: 0.9825\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 3.8620e-04 - accuracy: 0.9972 - val_loss: 0.0037 - val_accuracy: 0.9835\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 3.6760e-04 - accuracy: 0.9973 - val_loss: 0.0037 - val_accuracy: 0.9824\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 3.5857e-04 - accuracy: 0.9973 - val_loss: 0.0036 - val_accuracy: 0.9827\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 3.5176e-04 - accuracy: 0.9973 - val_loss: 0.0037 - val_accuracy: 0.9835\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 3.4213e-04 - accuracy: 0.9974 - val_loss: 0.0036 - val_accuracy: 0.9828\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 3.3624e-04 - accuracy: 0.9973 - val_loss: 0.0038 - val_accuracy: 0.9835\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 3.2678e-04 - accuracy: 0.9974 - val_loss: 0.0036 - val_accuracy: 0.9828\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 3.1918e-04 - accuracy: 0.9974 - val_loss: 0.0037 - val_accuracy: 0.9825\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 3.1117e-04 - accuracy: 0.9975 - val_loss: 0.0037 - val_accuracy: 0.9834\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 3.0613e-04 - accuracy: 0.9975 - val_loss: 0.0036 - val_accuracy: 0.9826\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 2.9775e-04 - accuracy: 0.9975 - val_loss: 0.0037 - val_accuracy: 0.9837\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 2.9477e-04 - accuracy: 0.9975 - val_loss: 0.0037 - val_accuracy: 0.9837\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 2.9845e-04 - accuracy: 0.9976 - val_loss: 0.0037 - val_accuracy: 0.9839\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 2.8752e-04 - accuracy: 0.9976 - val_loss: 0.0037 - val_accuracy: 0.9830\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 2.8585e-04 - accuracy: 0.9976 - val_loss: 0.0036 - val_accuracy: 0.9834\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 2.8212e-04 - accuracy: 0.9976 - val_loss: 0.0037 - val_accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=E,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0018 - accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0036688411476642683, 0.9832]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Testing')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "- Accuracy Exercise 3 = 88.22 %\n",
    "- Accuracy Exercise 4 = 98.28 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is higher, if we use keras. Also it's so much easier to use.\n",
    "\n",
    "Performance is similiar in this example, but it seems, that if you use keras it is maybe a bit less performant than pure Tensorflow. (https://wrosinski.github.io/deep-learning-frameworks/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
