{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layersizes, drop_rate=0.0):\n",
    "    \"\"\"\n",
    "    Provides an MLP model (using Sequential) with given layersizes. The last layer is a softmax layer.\n",
    "    Add for the hidden layer a dropout layer. Make sure that the dropout layer is applied after the affiine transformation and before the activation function.\n",
    "    As activation function use sigmoid.\n",
    "        \n",
    "    Arguments:\n",
    "    layersizes -- list of integers with the number of hidden units per layer. The last element is for MNIST 10.\n",
    "    drop_rate -- the drop rate for dropout\n",
    "    \n",
    "    \"\"\"\n",
    "    ### START YOUR CODE HERE ###\n",
    "\n",
    "    layers = []\n",
    "    layers.append(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "    for i in range (len(layersizes)-1):\n",
    "        layers.append(tf.keras.layers.Dense(layersizes[i], activation='sigmoid', name = \"hidden\"+str(i+1)))\n",
    "        if(drop_rate!=0.0):\n",
    "            layers.append(tf.keras.layers.Dropout(drop_rate))\n",
    "    layers.append(tf.keras.layers.Dense(layersizes[-1], activation='softmax'))\n",
    "    model= tf.keras.models.Sequential(layers)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### STOP YOUR CODE HERE ###\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 2.3097 - accuracy: 0.1119 - val_loss: 2.2989 - val_accuracy: 0.1144\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2981 - accuracy: 0.1143 - val_loss: 2.2965 - val_accuracy: 0.1135\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2960 - accuracy: 0.1139 - val_loss: 2.2946 - val_accuracy: 0.1135\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2938 - accuracy: 0.1137 - val_loss: 2.2921 - val_accuracy: 0.1205\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2914 - accuracy: 0.1148 - val_loss: 2.2895 - val_accuracy: 0.1162\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2886 - accuracy: 0.1207 - val_loss: 2.2866 - val_accuracy: 0.1197\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2854 - accuracy: 0.1364 - val_loss: 2.2832 - val_accuracy: 0.1135\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2816 - accuracy: 0.1495 - val_loss: 2.2790 - val_accuracy: 0.1159\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2772 - accuracy: 0.1627 - val_loss: 2.2741 - val_accuracy: 0.1466\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2718 - accuracy: 0.1835 - val_loss: 2.2678 - val_accuracy: 0.1975\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2650 - accuracy: 0.2221 - val_loss: 2.2602 - val_accuracy: 0.2570\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2563 - accuracy: 0.2708 - val_loss: 2.2501 - val_accuracy: 0.2376\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2451 - accuracy: 0.2861 - val_loss: 2.2371 - val_accuracy: 0.2615\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2302 - accuracy: 0.3113 - val_loss: 2.2196 - val_accuracy: 0.3049\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.2101 - accuracy: 0.3412 - val_loss: 2.1958 - val_accuracy: 0.3348\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.1821 - accuracy: 0.3641 - val_loss: 2.1625 - val_accuracy: 0.3998\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.1427 - accuracy: 0.3864 - val_loss: 2.1155 - val_accuracy: 0.4030\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.0872 - accuracy: 0.4060 - val_loss: 2.0488 - val_accuracy: 0.4047\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.0100 - accuracy: 0.4171 - val_loss: 1.9588 - val_accuracy: 0.4315\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 1.9091 - accuracy: 0.4354 - val_loss: 1.8464 - val_accuracy: 0.4417\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.7908 - accuracy: 0.4553 - val_loss: 1.7231 - val_accuracy: 0.4607\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.6699 - accuracy: 0.4763 - val_loss: 1.6056 - val_accuracy: 0.4837\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.5586 - accuracy: 0.4990 - val_loss: 1.5009 - val_accuracy: 0.5275\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.4609 - accuracy: 0.5282 - val_loss: 1.4099 - val_accuracy: 0.5426\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 1.3749 - accuracy: 0.5511 - val_loss: 1.3290 - val_accuracy: 0.5690\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2984 - accuracy: 0.5735 - val_loss: 1.2569 - val_accuracy: 0.5855\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.2299 - accuracy: 0.5911 - val_loss: 1.1921 - val_accuracy: 0.6083\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.1687 - accuracy: 0.6097 - val_loss: 1.1354 - val_accuracy: 0.6256\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 1.1149 - accuracy: 0.6261 - val_loss: 1.0847 - val_accuracy: 0.6411\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.0678 - accuracy: 0.6432 - val_loss: 1.0412 - val_accuracy: 0.6557\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.0271 - accuracy: 0.6589 - val_loss: 1.0038 - val_accuracy: 0.6629\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9917 - accuracy: 0.6702 - val_loss: 0.9701 - val_accuracy: 0.6861\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.9607 - accuracy: 0.6840 - val_loss: 0.9408 - val_accuracy: 0.6994\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.9332 - accuracy: 0.6960 - val_loss: 0.9148 - val_accuracy: 0.7107\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.9086 - accuracy: 0.7064 - val_loss: 0.8912 - val_accuracy: 0.7172\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8862 - accuracy: 0.7159 - val_loss: 0.8699 - val_accuracy: 0.7260\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8657 - accuracy: 0.7262 - val_loss: 0.8501 - val_accuracy: 0.7287\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.8466 - accuracy: 0.7330 - val_loss: 0.8318 - val_accuracy: 0.7359\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.8287 - accuracy: 0.7404 - val_loss: 0.8146 - val_accuracy: 0.7516\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.8119 - accuracy: 0.7491 - val_loss: 0.7977 - val_accuracy: 0.7538\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7959 - accuracy: 0.7553 - val_loss: 0.7819 - val_accuracy: 0.7646\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7804 - accuracy: 0.7624 - val_loss: 0.7663 - val_accuracy: 0.7713\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7657 - accuracy: 0.7689 - val_loss: 0.7521 - val_accuracy: 0.7760\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7514 - accuracy: 0.7770 - val_loss: 0.7378 - val_accuracy: 0.7826\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.7376 - accuracy: 0.7826 - val_loss: 0.7236 - val_accuracy: 0.7898\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.7241 - accuracy: 0.7895 - val_loss: 0.7105 - val_accuracy: 0.7936\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.7111 - accuracy: 0.7947 - val_loss: 0.6972 - val_accuracy: 0.7993\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.6984 - accuracy: 0.7997 - val_loss: 0.6843 - val_accuracy: 0.8066\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.6859 - accuracy: 0.8050 - val_loss: 0.6725 - val_accuracy: 0.8088\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.6738 - accuracy: 0.8103 - val_loss: 0.6601 - val_accuracy: 0.8138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b01f05d5f8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "#7.2 a)\n",
    "\n",
    "layersizes = [50,50,50,10]\n",
    "\n",
    "epochs = 50\n",
    "batchsize = 128 \n",
    "lr = 0.01\n",
    "drop_rate = 0.0\n",
    "run_name = \"no Dropout\"\n",
    "\n",
    "### STOP YOUR CODE HERE ###\n",
    "\n",
    "tensorboard_folder = \"tb_logs_keras\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "outdir = os.path.join(os.getcwd(), tensorboard_folder, current_time, run_name)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=outdir, histogram_freq=1, profile_batch=0)\n",
    "\n",
    "\n",
    "model = create_model(layersizes, drop_rate)    \n",
    "model.compile(optimizer=\"sgd\", learning_rate=lr, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, epochs=epochs, batch_size=batchsize,\n",
    "          validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 2.4376 - accuracy: 0.1012 - val_loss: 2.2985 - val_accuracy: 0.1135\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.3845 - accuracy: 0.1059 - val_loss: 2.2972 - val_accuracy: 0.1135\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3657 - accuracy: 0.1034 - val_loss: 2.2961 - val_accuracy: 0.1135\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3485 - accuracy: 0.1066 - val_loss: 2.2952 - val_accuracy: 0.1135\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3392 - accuracy: 0.1049 - val_loss: 2.2946 - val_accuracy: 0.1135\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3328 - accuracy: 0.1043 - val_loss: 2.2940 - val_accuracy: 0.1135\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3266 - accuracy: 0.1067 - val_loss: 2.2933 - val_accuracy: 0.1135\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3236 - accuracy: 0.1082 - val_loss: 2.2928 - val_accuracy: 0.1135\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3172 - accuracy: 0.1080 - val_loss: 2.2922 - val_accuracy: 0.1135\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3144 - accuracy: 0.1103 - val_loss: 2.2916 - val_accuracy: 0.1135\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3107 - accuracy: 0.1127 - val_loss: 2.2910 - val_accuracy: 0.1135\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3092 - accuracy: 0.1116 - val_loss: 2.2904 - val_accuracy: 0.1135\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3079 - accuracy: 0.1139 - val_loss: 2.2897 - val_accuracy: 0.1135\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.3054 - accuracy: 0.1158 - val_loss: 2.2890 - val_accuracy: 0.1135\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3042 - accuracy: 0.1146 - val_loss: 2.2882 - val_accuracy: 0.1135\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.3011 - accuracy: 0.1196 - val_loss: 2.2872 - val_accuracy: 0.1135\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 2.3007 - accuracy: 0.11 - 1s 17us/sample - loss: 2.3006 - accuracy: 0.1191 - val_loss: 2.2862 - val_accuracy: 0.1135\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2989 - accuracy: 0.1201 - val_loss: 2.2851 - val_accuracy: 0.1142\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2980 - accuracy: 0.1235 - val_loss: 2.2837 - val_accuracy: 0.1135\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2958 - accuracy: 0.1268 - val_loss: 2.2822 - val_accuracy: 0.1135\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2952 - accuracy: 0.1264 - val_loss: 2.2807 - val_accuracy: 0.1179\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2925 - accuracy: 0.1286 - val_loss: 2.2784 - val_accuracy: 0.1163\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2900 - accuracy: 0.1324 - val_loss: 2.2758 - val_accuracy: 0.1397\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2886 - accuracy: 0.1327 - val_loss: 2.2730 - val_accuracy: 0.1819\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2854 - accuracy: 0.1374 - val_loss: 2.2694 - val_accuracy: 0.1876\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2822 - accuracy: 0.1415 - val_loss: 2.2652 - val_accuracy: 0.1926\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2781 - accuracy: 0.1441 - val_loss: 2.2598 - val_accuracy: 0.2122\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2751 - accuracy: 0.1457 - val_loss: 2.2536 - val_accuracy: 0.2420\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2686 - accuracy: 0.1549 - val_loss: 2.2451 - val_accuracy: 0.2356\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2636 - accuracy: 0.1562 - val_loss: 2.2351 - val_accuracy: 0.2253\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2532 - accuracy: 0.1649 - val_loss: 2.2219 - val_accuracy: 0.2598\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2436 - accuracy: 0.1703 - val_loss: 2.2050 - val_accuracy: 0.2732\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2304 - accuracy: 0.1802 - val_loss: 2.1843 - val_accuracy: 0.3498\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2132 - accuracy: 0.1872 - val_loss: 2.1572 - val_accuracy: 0.3319\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.1922 - accuracy: 0.1953 - val_loss: 2.1240 - val_accuracy: 0.3321\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.1644 - accuracy: 0.2052 - val_loss: 2.0847 - val_accuracy: 0.3313\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.1367 - accuracy: 0.2159 - val_loss: 2.0411 - val_accuracy: 0.3260\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.1045 - accuracy: 0.2240 - val_loss: 1.9939 - val_accuracy: 0.3655\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0689 - accuracy: 0.2356 - val_loss: 1.9468 - val_accuracy: 0.3677\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0371 - accuracy: 0.2404 - val_loss: 1.9010 - val_accuracy: 0.3939\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0024 - accuracy: 0.2519 - val_loss: 1.8573 - val_accuracy: 0.4098\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9702 - accuracy: 0.2615 - val_loss: 1.8167 - val_accuracy: 0.3899\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9382 - accuracy: 0.2686 - val_loss: 1.7787 - val_accuracy: 0.4132\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9102 - accuracy: 0.2770 - val_loss: 1.7435 - val_accuracy: 0.3980\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.8785 - accuracy: 0.2843 - val_loss: 1.7094 - val_accuracy: 0.4088\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8549 - accuracy: 0.2940 - val_loss: 1.6767 - val_accuracy: 0.4185\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8209 - accuracy: 0.3005 - val_loss: 1.6441 - val_accuracy: 0.4245 accuracy: 0.30\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.7969 - accuracy: 0.3085 - val_loss: 1.6120 - val_accuracy: 0.4216\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7683 - accuracy: 0.3202 - val_loss: 1.5812 - val_accuracy: 0.4314\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.7475 - accuracy: 0.3282 - val_loss: 1.5516 - val_accuracy: 0.4497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b03e8c4a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "#7.2 b)\n",
    "\n",
    "layersizes = [50,50,50,10]\n",
    "\n",
    "epochs = 50\n",
    "batchsize = 128 \n",
    "lr = 0.01\n",
    "drop_rate = 0.4\n",
    "run_name = \"Dropout 0.4\"\n",
    "\n",
    "### STOP YOUR CODE HERE ###\n",
    "\n",
    "tensorboard_folder = \"tb_logs_keras\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "outdir = os.path.join(os.getcwd(), tensorboard_folder, current_time, run_name)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=outdir, histogram_freq=1, profile_batch=0)\n",
    "\n",
    "\n",
    "model = create_model(layersizes, drop_rate)    \n",
    "model.compile(optimizer=\"sgd\", learning_rate=lr, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, epochs=epochs, batch_size=batchsize,\n",
    "          validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "\n",
    "def step_decay(epoch):\n",
    "   initial_lrate = 0.1\n",
    "   drop = 0.5\n",
    "   epochs_drop = 20.0\n",
    "   lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/70\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 2.4026 - accuracy: 0.0993 - val_loss: 2.3001 - val_accuracy: 0.1135\n",
      "Epoch 2/70\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 2.3753 - accuracy: 0.1012 - val_loss: 2.2991 - val_accuracy: 0.1135\n",
      "Epoch 3/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.3598 - accuracy: 0.1005 - val_loss: 2.2985 - val_accuracy: 0.1135\n",
      "Epoch 4/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.3454 - accuracy: 0.1025 - val_loss: 2.2974 - val_accuracy: 0.1135\n",
      "Epoch 5/70\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.3359 - accuracy: 0.1025 - val_loss: 2.2974 - val_accuracy: 0.1135\n",
      "Epoch 6/70\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.3312 - accuracy: 0.1036 - val_loss: 2.2966 - val_accuracy: 0.1135\n",
      "Epoch 7/70\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.3249 - accuracy: 0.1047 - val_loss: 2.2966 - val_accuracy: 0.1135\n",
      "Epoch 8/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3228 - accuracy: 0.1045 - val_loss: 2.2957 - val_accuracy: 0.1135\n",
      "Epoch 9/70\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 2.3179 - accuracy: 0.10 - 1s 16us/sample - loss: 2.3176 - accuracy: 0.1072 - val_loss: 2.2955 - val_accuracy: 0.1135\n",
      "Epoch 10/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3166 - accuracy: 0.1058 - val_loss: 2.2953 - val_accuracy: 0.1135\n",
      "Epoch 11/70\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.3132 - accuracy: 0.1088 - val_loss: 2.2949 - val_accuracy: 0.1135\n",
      "Epoch 12/70\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3118 - accuracy: 0.1080 - val_loss: 2.2945 - val_accuracy: 0.1135\n",
      "Epoch 13/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.3083 - accuracy: 0.1103 - val_loss: 2.2940 - val_accuracy: 0.1135\n",
      "Epoch 14/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3079 - accuracy: 0.1105 - val_loss: 2.2936 - val_accuracy: 0.1135\n",
      "Epoch 15/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3064 - accuracy: 0.1117 - val_loss: 2.2933 - val_accuracy: 0.1135\n",
      "Epoch 16/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3040 - accuracy: 0.1123 - val_loss: 2.2928 - val_accuracy: 0.1135\n",
      "Epoch 17/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3051 - accuracy: 0.1126 - val_loss: 2.2924 - val_accuracy: 0.1135\n",
      "Epoch 18/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3038 - accuracy: 0.1146 - val_loss: 2.2919 - val_accuracy: 0.1135\n",
      "Epoch 19/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3033 - accuracy: 0.1131 - val_loss: 2.2913 - val_accuracy: 0.1135\n",
      "Epoch 20/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3003 - accuracy: 0.1168 - val_loss: 2.2907 - val_accuracy: 0.1135\n",
      "Epoch 21/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3007 - accuracy: 0.1158 - val_loss: 2.2899 - val_accuracy: 0.1135\n",
      "Epoch 22/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2998 - accuracy: 0.1169 - val_loss: 2.2892 - val_accuracy: 0.1135\n",
      "Epoch 23/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2985 - accuracy: 0.1179 - val_loss: 2.2884 - val_accuracy: 0.1139\n",
      "Epoch 24/70\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 2.2972 - accuracy: 0.1190 - val_loss: 2.2874 - val_accuracy: 0.1139\n",
      "Epoch 25/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2984 - accuracy: 0.1189 - val_loss: 2.2865 - val_accuracy: 0.1135\n",
      "Epoch 26/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2953 - accuracy: 0.1237 - val_loss: 2.2851 - val_accuracy: 0.1231\n",
      "Epoch 27/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2939 - accuracy: 0.1246 - val_loss: 2.2837 - val_accuracy: 0.1302\n",
      "Epoch 28/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2918 - accuracy: 0.1258 - val_loss: 2.2820 - val_accuracy: 0.1618\n",
      "Epoch 29/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2919 - accuracy: 0.1272 - val_loss: 2.2801 - val_accuracy: 0.1709\n",
      "Epoch 30/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2899 - accuracy: 0.1299 - val_loss: 2.2780 - val_accuracy: 0.1480\n",
      "Epoch 31/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2879 - accuracy: 0.1322 - val_loss: 2.2754 - val_accuracy: 0.1621\n",
      "Epoch 32/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2857 - accuracy: 0.1328 - val_loss: 2.2721 - val_accuracy: 0.1864\n",
      "Epoch 33/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2839 - accuracy: 0.1346 - val_loss: 2.2682 - val_accuracy: 0.1993\n",
      "Epoch 34/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2797 - accuracy: 0.1381 - val_loss: 2.2633 - val_accuracy: 0.1867\n",
      "Epoch 35/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2750 - accuracy: 0.1423 - val_loss: 2.2573 - val_accuracy: 0.2012\n",
      "Epoch 36/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2695 - accuracy: 0.1463 - val_loss: 2.2495 - val_accuracy: 0.2037\n",
      "Epoch 37/70\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2639 - accuracy: 0.1491 - val_loss: 2.2395 - val_accuracy: 0.2026\n",
      "Epoch 38/70\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.2556 - accuracy: 0.1560 - val_loss: 2.2267 - val_accuracy: 0.2047\n",
      "Epoch 39/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2439 - accuracy: 0.1605 - val_loss: 2.2095 - val_accuracy: 0.2092\n",
      "Epoch 40/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2290 - accuracy: 0.1663 - val_loss: 2.1867 - val_accuracy: 0.2104\n",
      "Epoch 41/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.2126 - accuracy: 0.1698 - val_loss: 2.1578 - val_accuracy: 0.2163\n",
      "Epoch 42/70\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1880 - accuracy: 0.1775 - val_loss: 2.1211 - val_accuracy: 0.2218\n",
      "Epoch 43/70\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1580 - accuracy: 0.1860 - val_loss: 2.0769 - val_accuracy: 0.2326\n",
      "Epoch 44/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.1225 - accuracy: 0.1955 - val_loss: 2.0272 - val_accuracy: 0.2395\n",
      "Epoch 45/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.0871 - accuracy: 0.2016 - val_loss: 1.9773 - val_accuracy: 0.2432\n",
      "Epoch 46/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0484 - accuracy: 0.2040 - val_loss: 1.9298 - val_accuracy: 0.2467\n",
      "Epoch 47/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.0112 - accuracy: 0.2116 - val_loss: 1.8896 - val_accuracy: 0.2636\n",
      "Epoch 48/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.9785 - accuracy: 0.2183 - val_loss: 1.8562 - val_accuracy: 0.2652\n",
      "Epoch 49/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9530 - accuracy: 0.2212 - val_loss: 1.8309 - val_accuracy: 0.2591\n",
      "Epoch 50/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9302 - accuracy: 0.2275 - val_loss: 1.8102 - val_accuracy: 0.2745\n",
      "Epoch 51/70\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.9120 - accuracy: 0.2305 - val_loss: 1.7943 - val_accuracy: 0.2699\n",
      "Epoch 52/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.8936 - accuracy: 0.2345 - val_loss: 1.7809 - val_accuracy: 0.2650\n",
      "Epoch 53/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.8791 - accuracy: 0.2368 - val_loss: 1.7697 - val_accuracy: 0.2763\n",
      "Epoch 54/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8667 - accuracy: 0.2414 - val_loss: 1.7595 - val_accuracy: 0.3140\n",
      "Epoch 55/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8573 - accuracy: 0.2427 - val_loss: 1.7500 - val_accuracy: 0.3054\n",
      "Epoch 56/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.8451 - accuracy: 0.2459 - val_loss: 1.7413 - val_accuracy: 0.3444\n",
      "Epoch 57/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.8390 - accuracy: 0.2494 - val_loss: 1.7316 - val_accuracy: 0.3456\n",
      "Epoch 58/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8271 - accuracy: 0.2531 - val_loss: 1.7219 - val_accuracy: 0.3614\n",
      "Epoch 59/70\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.8161 - accuracy: 0.2596 - val_loss: 1.7111 - val_accuracy: 0.3815\n",
      "Epoch 60/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.8057 - accuracy: 0.2668 - val_loss: 1.6993 - val_accuracy: 0.3938\n",
      "Epoch 61/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.7962 - accuracy: 0.2695 - val_loss: 1.6864 - val_accuracy: 0.3930\n",
      "Epoch 62/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.7853 - accuracy: 0.2747 - val_loss: 1.6720 - val_accuracy: 0.4176\n",
      "Epoch 63/70\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 1.7743 - accuracy: 0.27 - 1s 15us/sample - loss: 1.7743 - accuracy: 0.2789 - val_loss: 1.6557 - val_accuracy: 0.4121\n",
      "Epoch 64/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7587 - accuracy: 0.2881 - val_loss: 1.6377 - val_accuracy: 0.4564\n",
      "Epoch 65/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7475 - accuracy: 0.2939 - val_loss: 1.6175 - val_accuracy: 0.4477\n",
      "Epoch 66/70\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.7296 - accuracy: 0.3024 - val_loss: 1.5955 - val_accuracy: 0.4608\n",
      "Epoch 67/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7125 - accuracy: 0.3118 - val_loss: 1.5707 - val_accuracy: 0.4704\n",
      "Epoch 68/70\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.6947 - accuracy: 0.3200 - val_loss: 1.5443 - val_accuracy: 0.4716\n",
      "Epoch 69/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6781 - accuracy: 0.3316 - val_loss: 1.5164 - val_accuracy: 0.4790\n",
      "Epoch 70/70\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6580 - accuracy: 0.3344 - val_loss: 1.4878 - val_accuracy: 0.4804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b048db4128>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START YOUR CODE HERE ###\n",
    "\n",
    "layersizes = [50,50,50,10]\n",
    "\n",
    "epochs = 70\n",
    "batchsize = 128 \n",
    "lr = 0.01\n",
    "drop_rate = 0.4\n",
    "run_name = \"Dropout 0.4 and modified LR\"\n",
    "\n",
    "### STOP YOUR CODE HERE ###\n",
    "\n",
    "tensorboard_folder = \"tb_logs_keras\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "outdir = os.path.join(os.getcwd(), tensorboard_folder, current_time, run_name)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=outdir, histogram_freq=1, profile_batch=0)\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "\n",
    "model = create_model(layersizes, drop_rate)    \n",
    "model.compile(optimizer=\"sgd\", learning_rate=lrate, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, epochs=epochs, batch_size=batchsize,\n",
    "          validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
